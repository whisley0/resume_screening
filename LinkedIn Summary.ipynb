{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fd93e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parameters\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d8f611ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elam2\\AppData\\Local\\Temp/ipykernel_19940/221464012.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "\n",
    "PATH = \"chromedriver.exe\" \n",
    "\n",
    "driver = webdriver.Chrome(PATH) \n",
    "\n",
    "driver.get(\"https://www.linkedin.com\")\n",
    "\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d593f564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elam2\\AppData\\Local\\Temp/ipykernel_19940/1944586232.py:1: DeprecationWarning: find_element_by_class_name is deprecated. Please use find_element(by=By.CLASS_NAME, value=name) instead\n",
      "  username = driver.find_element_by_class_name('input__input')\n",
      "C:\\Users\\elam2\\AppData\\Local\\Temp/ipykernel_19940/1944586232.py:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  password = driver.find_element_by_id('session_password')\n"
     ]
    }
   ],
   "source": [
    "username = driver.find_element_by_class_name('input__input')\n",
    "\n",
    "username.send_keys('edward_lam@vfc.com')\n",
    "\n",
    "sleep(0.5)\n",
    "\n",
    "password = driver.find_element_by_id('session_password')\n",
    "\n",
    "password.send_keys('Today2022') \n",
    "\n",
    "sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4a57b6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elam2\\AppData\\Local\\Temp/ipykernel_19940/1689031501.py:1: DeprecationWarning: find_element_by_class_name is deprecated. Please use find_element(by=By.CLASS_NAME, value=name) instead\n",
      "  log_in_button = driver.find_element_by_class_name('sign-in-form__submit-button')\n"
     ]
    }
   ],
   "source": [
    "log_in_button = driver.find_element_by_class_name('sign-in-form__submit-button') \n",
    "\n",
    "log_in_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "474bc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver.get(\"https://www.google.com\")\n",
    "\n",
    "sleep(3)\n",
    "\n",
    "#search_query = driver.find_element_by_name('q')\n",
    "search_query = driver.find_element(by=By.NAME, value='q')\n",
    "\n",
    "search_query.send_keys('site:linkedin.com/in/ AND \"CHONG FAI EDWARD LAM\" AND \"VF\"')\n",
    "\n",
    "sleep(0.5)\n",
    "\n",
    "search_query.send_keys(Keys.RETURN)\n",
    "\n",
    "sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "826789d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elam2\\AppData\\Local\\Temp/ipykernel_19940/301742697.py:2: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  myLinks=driver.find_elements_by_xpath('//*[@id=\"rso\"]/div[1]/div/div/div[1]/div/a')\n"
     ]
    }
   ],
   "source": [
    "#linkedin_urls = driver.find_elements_by_class_name('yuRUbf')\n",
    "myLinks=driver.find_elements_by_xpath('//*[@id=\"rso\"]/div[1]/div/div/div[1]/div/a')\n",
    "\n",
    "#candidate_urls = [url.get_attribute('href') for url in linkedin_urls]\n",
    "sleep(0.5)\n",
    "\n",
    "candidate_url = []\n",
    "\n",
    "for link in myLinks:\n",
    "    candidate_url.append(link.get_attribute(\"href\"))\n",
    "\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ec96e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(candidate_url[0])\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6707bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsel import Selector \n",
    "\n",
    "sel = Selector(text=driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a422e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get basic info from profile\n",
    "name = sel.xpath('/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[1]/div[1]/h1/text()').extract_first()\n",
    "\n",
    "if name:\n",
    "    name = name.strip()\n",
    "\n",
    "job_title = sel.xpath('/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[1]/div[2]/text()').extract_first()\n",
    "\n",
    "if job_title:\n",
    "    job_title = job_title.strip()\n",
    "\n",
    "company = sel.xpath('//*[@id=\"ember36\"]/div[2]/div[2]/ul/li[1]/a/h2/div/text()').extract_first()\n",
    "\n",
    "if company:\n",
    "    company = company.strip()\n",
    "\n",
    "university = sel.xpath('//*[@id=\"ember36\"]/div[2]/div[2]/ul/li[2]/a/h2/div/text()').extract_first()\n",
    "\n",
    "if university:\n",
    "    university = university.strip()\n",
    "\n",
    "location = sel.xpath('//*[@id=\"ember36\"]/div[2]/div[2]/div[2]/span[1]/text()').extract_first()\n",
    "\n",
    "if location:\n",
    "    location = location.strip()\n",
    "    \n",
    "about = sel.xpath('//*[@id=\"ember212\"]/div[3]/div/div/div/span[1]/text()[1]').extract_first()\n",
    "\n",
    "if about:\n",
    "    about = about.strip()\n",
    "\n",
    "linkedin_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9e1ee56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build details page from homepage\n",
    "linkedin_url = linkedin_url.split('?')[0]\n",
    "\n",
    "activity_url = linkedin_url + 'recent-activity'\n",
    "interest_url = linkedin_url + 'details/interests/'\n",
    "skills_url = linkedin_url + 'details/skills/'\n",
    "languages_url = linkedin_url + 'details/languages/'\n",
    "exp_url = linkedin_url + 'details/experience/'\n",
    "education_url = linkedin_url + 'details/education/'\n",
    "license_url = linkedin_url + 'details/certifications/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "eb573503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "# Collect data into fixed-length chunks or blocks\"\n",
    "# grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(fillvalue=fillvalue, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5a0abfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Senior System Analyst',\n",
       "  'VF Corporation · Full-time',\n",
       "  'May 2019 - Present · 2 yrs 11 mos',\n",
       "  'Hong Kong',\n",
       "  '- Experience in overseeing data ingestion project to ingest corporate data from multiple data sources to data warehouse in Amazon AWS. \\n\\n- Hand-on experience from data mapping, data ingestion using Airflow and Glue to S3 and redshift data warehouse as well as visualization of the data using Tableau Dashboard.\\n\\n- Specialized in NLP to classify user reviews into topics that gives business users the insight on the business trend, summary of user feedback down to the product level and giving out alert in case of major quality issues  \\n\\n- Data Collection from web scraping and ETL using python of the online store, perform analysis and create visualization on tableau/Flask web app to show the dominant customer comments of specific product\\n\\n- Analyze product by clustering and perform Inventory forecast using various machine learning such as lightGBM & ARIMA \\n\\n- Automation of the business process with python script/Knime/IIS server\\n\\n- Perform Recency/Frequency/Monetary analysis using sales data and determine segmentation of the customers based on the result.\\n\\nLead in several projects, in both waterfall and agile methodology. I have been working closely with different business parties to collect requirement, acted as a facilitator between them and external vendor and drive the project until the end of its lifecycle. These projects ranged from Smartsheet approval workflow, web applications combine of python and Flask to Data ingestion to AWS data lake.\\n\\nInstructors in training of ‘Knime’ to internal business teams, Knime workflow creators, designer of visualizations on tableau.'],\n",
       " ['Business Analyst',\n",
       "  'Ansell',\n",
       "  'Apr 2015 - May 2019 · 4 yrs 2 mos',\n",
       "  'A member of the international strategy team. Oversees a series of projects that enable global sales users to interact with customers in regions including Australia, Mainland China, Malaysia, Korea, and Japan. Collaborates with cross-functional teams, including Developers, to share design plans and prioritize tickets and scheduling. Maximizes network performance by translating business needs to tangible technical requirements. Utilizes COMINDWORK software to write and rate tickets. Trains new users on the framework concept in English.'],\n",
       " ['Engineer',\n",
       "  'HKT',\n",
       "  'Feb 2013 - Apr 2015 · 2 yrs 3 mos',\n",
       "  'Managed various development project including a new bank messaging portal. Created daily and monthly reports. Interfaced with customers and internal developers to prioritize technical issues. Oversaw the technical deployment process and quickly resolved unexpected technical issues. Adhered to ISO standards. Conducted annual internal audits for interdepartmental teams.']]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get details of the profile page\n",
    "#for span in sel.xpath('//span'):\n",
    "    \n",
    "#    print(span.xpath('./text()').get())\n",
    "\n",
    "#get experience\n",
    "experience, role = get_content_from_url(exp_url, driver)\n",
    "role_n_exp = breakdown_list(experience, role)\n",
    "role_n_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b83ce113",
   "metadata": {},
   "outputs": [],
   "source": [
    "Start_stop = '\\n      Status is '\n",
    "\n",
    "role_n_exp = []\n",
    "detail = []\n",
    "\n",
    "for exp in experience[1:]:\n",
    "    \n",
    "    if exp != Start_stop:\n",
    "        \n",
    "        if any(exp in s for s in role):\n",
    "            \n",
    "            role_n_exp.append(detail)\n",
    "            detail = []\n",
    "            \n",
    "        detail.append(exp)\n",
    "        \n",
    "role_n_exp = role_n_exp[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "16b2c104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Senior System Analyst',\n",
       "  'VF Corporation · Full-time',\n",
       "  'May 2019 - Present · 2 yrs 11 mos',\n",
       "  'Hong Kong',\n",
       "  '- Experience in overseeing data ingestion project to ingest corporate data from multiple data sources to data warehouse in Amazon AWS. \\n\\n- Hand-on experience from data mapping, data ingestion using Airflow and Glue to S3 and redshift data warehouse as well as visualization of the data using Tableau Dashboard.\\n\\n- Specialized in NLP to classify user reviews into topics that gives business users the insight on the business trend, summary of user feedback down to the product level and giving out alert in case of major quality issues  \\n\\n- Data Collection from web scraping and ETL using python of the online store, perform analysis and create visualization on tableau/Flask web app to show the dominant customer comments of specific product\\n\\n- Analyze product by clustering and perform Inventory forecast using various machine learning such as lightGBM & ARIMA \\n\\n- Automation of the business process with python script/Knime/IIS server\\n\\n- Perform Recency/Frequency/Monetary analysis using sales data and determine segmentation of the customers based on the result.\\n\\nLead in several projects, in both waterfall and agile methodology. I have been working closely with different business parties to collect requirement, acted as a facilitator between them and external vendor and drive the project until the end of its lifecycle. These projects ranged from Smartsheet approval workflow, web applications combine of python and Flask to Data ingestion to AWS data lake.\\n\\nInstructors in training of ‘Knime’ to internal business teams, Knime workflow creators, designer of visualizations on tableau.'],\n",
       " ['Business Analyst',\n",
       "  'Ansell',\n",
       "  'Apr 2015 - May 2019 · 4 yrs 2 mos',\n",
       "  'A member of the international strategy team. Oversees a series of projects that enable global sales users to interact with customers in regions including Australia, Mainland China, Malaysia, Korea, and Japan. Collaborates with cross-functional teams, including Developers, to share design plans and prioritize tickets and scheduling. Maximizes network performance by translating business needs to tangible technical requirements. Utilizes COMINDWORK software to write and rate tickets. Trains new users on the framework concept in English.'],\n",
       " ['Engineer',\n",
       "  'HKT',\n",
       "  'Feb 2013 - Apr 2015 · 2 yrs 3 mos',\n",
       "  'Managed various development project including a new bank messaging portal. Created daily and monthly reports. Interfaced with customers and internal developers to prioritize technical issues. Oversaw the technical deployment process and quickly resolved unexpected technical issues. Adhered to ISO standards. Conducted annual internal audits for interdepartmental teams.']]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role_n_exp = breakdown_list(experience, role)\n",
    "role_n_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d05f712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def :\n",
    "    \n",
    "    full_list = []\n",
    "    item_list = []\n",
    "\n",
    "    driver.get(exp_url)\n",
    "    sleep(3)\n",
    "\n",
    "    sel = Selector(text=driver.page_source)\n",
    "    \n",
    "    for span in sel.xpath(\"//span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "        full_list.append(span.xpath('./text()').get())\n",
    "\n",
    "    for span in sel.xpath(\"//span[contains(@class, 't-bold mr1')]/span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "        item_list.append(span.xpath('./text()').get())\n",
    "        \n",
    "    return full_list, item_list\n",
    "\n",
    "def breakdown_list(full_list, item_list):\n",
    "    \n",
    "    final_list = []\n",
    "    sub_list = []\n",
    "    \n",
    "    for item in full_list[1:]:\n",
    "        if item != Start_stop:\n",
    "            if any(item == s for s in item_list):\n",
    "            \n",
    "                final_list.append(sub_list)\n",
    "                sub_list = []\n",
    "                \n",
    "            sub_list.append(item)\n",
    "\n",
    "    return final_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a81aa6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior System Analyst',\n",
       " 'VF Corporation · Full-time',\n",
       " 'May 2019 - Present · 2 yrs 11 mos',\n",
       " 'Hong Kong',\n",
       " '- Experience in overseeing data ingestion project to ingest corporate data from multiple data sources to data warehouse in Amazon AWS. \\n\\n- Hand-on experience from data mapping, data ingestion using Airflow and Glue to S3 and redshift data warehouse as well as visualization of the data using Tableau Dashboard.\\n\\n- Specialized in NLP to classify user reviews into topics that gives business users the insight on the business trend, summary of user feedback down to the product level and giving out alert in case of major quality issues  \\n\\n- Data Collection from web scraping and ETL using python of the online store, perform analysis and create visualization on tableau/Flask web app to show the dominant customer comments of specific product\\n\\n- Analyze product by clustering and perform Inventory forecast using various machine learning such as lightGBM & ARIMA \\n\\n- Automation of the business process with python script/Knime/IIS server\\n\\n- Perform Recency/Frequency/Monetary analysis using sales data and determine segmentation of the customers based on the result.\\n\\nLead in several projects, in both waterfall and agile methodology. I have been working closely with different business parties to collect requirement, acted as a facilitator between them and external vendor and drive the project until the end of its lifecycle. These projects ranged from Smartsheet approval workflow, web applications combine of python and Flask to Data ingestion to AWS data lake.\\n\\nInstructors in training of ‘Knime’ to internal business teams, Knime workflow creators, designer of visualizations on tableau.']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role_n_exp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "32459183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get lanugage info\n",
    "\n",
    "language = []\n",
    "lang = []\n",
    "\n",
    "driver.get(languages_url)\n",
    "sleep(3)\n",
    "\n",
    "sel = Selector(text=driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2a6a28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for span in sel.xpath(\"//span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    language.append(span.xpath('./text()').get())\n",
    "\n",
    "for span in sel.xpath(\"//span[contains(@class, 't-bold mr1')]/span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    lang.append(span.xpath('./text()').get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ac7c2399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Chinese', 'Native or bilingual proficiency'],\n",
       " ['English', 'Native or bilingual proficiency'],\n",
       " ['French', 'Full professional proficiency'],\n",
       " ['Japanese', 'Elementary proficiency']]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_list = []\n",
    "\n",
    "for a, b in grouper(language[1:], 2):\n",
    "    language_list.append([a, b])\n",
    "    \n",
    "language_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7827ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get details of the skills page\n",
    "#//tr[not(@id) and not(@class)]\n",
    "#get lanugage info\n",
    "\n",
    "skill = []\n",
    "\n",
    "driver.get(skills_url)\n",
    "sleep(3)\n",
    "\n",
    "sel = Selector(text=driver.page_source)\n",
    "\n",
    "for span in sel.xpath(\"//span[contains(@class, 't-bold mr1')]/span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    skill.append(span.xpath('./text()').get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8b647fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get details of the interests page\n",
    "interest = []\n",
    "interest_desc = []\n",
    "\n",
    "driver.get(interest_url)\n",
    "sleep(3)\n",
    "\n",
    "sel = Selector(text=driver.page_source)\n",
    "\n",
    "for span in sel.xpath(\"//span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    interest_desc.append(span.xpath('./text()').get())\n",
    "\n",
    "for span in sel.xpath(\"//span[contains(@class, 't-bold mr1')]/span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    interest.append(span.xpath('./text()').get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "194e8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_list = []\n",
    "interest_detail = []\n",
    "\n",
    "for interest_ in interest_desc:\n",
    "    \n",
    "    if interest_ != Start_stop:\n",
    "        \n",
    "        if any(interest_ in s for s in interest):\n",
    "            \n",
    "            interest_list.append(interest_detail)\n",
    "            interest_detail = []\n",
    "            \n",
    "        interest_detail.append(interest_)\n",
    "        \n",
    "interest_list = interest_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0ad04c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get details of the education page\n",
    "education = []\n",
    "education_desc = []\n",
    "\n",
    "driver.get(education_url)\n",
    "sleep(3)\n",
    "\n",
    "sel = Selector(text=driver.page_source)\n",
    "\n",
    "for span in sel.xpath(\"//span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    education_desc.append(span.xpath('./text()').get())\n",
    "\n",
    "for span in sel.xpath(\"//span[contains(@class, 't-bold mr1')]/span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    education.append(span.xpath('./text()').get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fe30c493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CUHK Business School',\n",
       "  \"Master's degree, Business Administration and Management, General\",\n",
       "  '2013 - 2015'],\n",
       " ['McGill University',\n",
       "  \"Bachelor's degree, Electrical and Electronics Engineering\",\n",
       "  '2003 - 2008']]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_list = []\n",
    "\n",
    "for a, b, c in grouper(education_desc[1:[idx for idx, s in enumerate(education_desc[1:]) if Start_stop in s][0]+1], 3):\n",
    "    education_list.append([a, b, c])\n",
    "    \n",
    "education_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c036fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get details of the license page\n",
    "license = []\n",
    "license_desc = []\n",
    "\n",
    "driver.get(license_url)\n",
    "sleep(3)\n",
    "\n",
    "sel = Selector(text=driver.page_source)\n",
    "\n",
    "for span in sel.xpath(\"//span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    license_desc.append(span.xpath('./text()').get())\n",
    "\n",
    "for span in sel.xpath(\"//span[contains(@class, 't-bold mr1')]/span[contains(@class, 'visually-hidden')]\"):\n",
    "    \n",
    "    license.append(span.xpath('./text()').get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "75ca8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "license_n_cert = []\n",
    "license_detail = []\n",
    "\n",
    "for lic in license_desc[1:]:\n",
    "    \n",
    "    if lic != Start_stop:\n",
    "        \n",
    "        if any(lic == s for s in license):\n",
    "            \n",
    "            license_n_cert.append(license_detail)\n",
    "            license_detail = []\n",
    "            \n",
    "        license_detail.append(lic)\n",
    "        \n",
    "license_n_cert = license_n_cert[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c2216f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Neo4j Certified Professional',\n",
       "  'Neo4j',\n",
       "  'Issued Jan 2022 · No Expiration Date',\n",
       "  'Credential ID 17346179'],\n",
       " ['Tableau Desktop Specialist',\n",
       "  'Tableau',\n",
       "  'Issued May 2020 · No Expiration Date'],\n",
       " ['Machine Learning',\n",
       "  'Coursera',\n",
       "  'Issued Sep 2018 · No Expiration Date',\n",
       "  'Credential ID ZY9X2QSMLAFL'],\n",
       " ['Nanodegree of Artificial Intelligence',\n",
       "  'Udacity',\n",
       "  'Issued Apr 2018 · No Expiration Date'],\n",
       " ['Nanodegree of Deep Learning',\n",
       "  'Udacity',\n",
       "  'Issued Mar 2018 · No Expiration Date'],\n",
       " ['Professional Scrum Master I',\n",
       "  'Scrum.org',\n",
       "  'Issued Jul 2016 · No Expiration Date'],\n",
       " ['Big Data and Social Analytics',\n",
       "  'MIT - Experimental Learning',\n",
       "  'Issued Jun 2016 · No Expiration Date',\n",
       "  'Credential ID Accredible-10358844'],\n",
       " ['Cisco Certified Network Professional',\n",
       "  'Cisco Career Certifications',\n",
       "  'Issued Apr 2015 · No Expiration Date'],\n",
       " ['IMS Internal Auditor for ISO 9001:2008 and ISO 27001: 2013',\n",
       "  'British Standards Institution',\n",
       "  'Issued Jun 2014 · No Expiration Date'],\n",
       " ['Android 2.3 app Development: Certificate of Training',\n",
       "  'Hong Kong Wireless Development Centre Certifications',\n",
       "  'Issued Sep 2011 · No Expiration Date']]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_n_cert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9cc5130e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neo4j Certified Professional',\n",
       " 'Tableau Desktop Specialist',\n",
       " 'Machine Learning',\n",
       " 'Nanodegree of Artificial Intelligence',\n",
       " 'Nanodegree of Deep Learning',\n",
       " 'Professional Scrum Master I',\n",
       " 'Big Data and Social Analytics',\n",
       " 'Cisco Certified Network Professional',\n",
       " 'IMS Internal Auditor for ISO 9001:2008 and ISO 27001: 2013',\n",
       " 'Android 2.3 app Development: Certificate of Training',\n",
       " 'Oracle 11g DBA OCA Certification']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bc935588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Jon Fortt',\n",
       "  'CNBC Anchor; Fortt Knox Host; Creator of The Black Experience in America: The Course',\n",
       "  '215,390 followers'],\n",
       " ['Phil Baumann',\n",
       "  'Solutions Director, C3i Solutions, an HCL Technologies company',\n",
       "  '103,731 followers'],\n",
       " ['Li & Fung', '159,789 followers'],\n",
       " ['MACLEANS Consulting International Limited', '3,203 followers'],\n",
       " ['Ansell', '89,843 followers'],\n",
       " ['csl', '5,977 followers'],\n",
       " ['fifty-five', '47,608 followers'],\n",
       " ['invalid15095651', '3,373 followers'],\n",
       " ['ROCHE ltd, Consulting Group', '6,838 followers'],\n",
       " ['3T Consulting - \"Reliable & professional business partner in Asia\"',\n",
       "  '540 followers'],\n",
       " ['Motorola Solutions', '336,590 followers'],\n",
       " ['Lidl Asia Pte. Limited', '37,004 followers'],\n",
       " ['Accenture', '8,440,271 followers'],\n",
       " ['Venturenix', '18,076 followers'],\n",
       " ['Verizon', '1,256,301 followers'],\n",
       " ['SEDONA FRANCE', '4,107 followers'],\n",
       " ['McGill University', '373,347 followers'],\n",
       " ['Tetra Tech', '197,815 followers'],\n",
       " ['Google', '24,239,818 followers'],\n",
       " ['Tetra Tech au Québec', '6,871 followers'],\n",
       " ['Coca-Cola Canada Bottling Limited', '82,982 followers'],\n",
       " ['CUHK Business School', '13,876 followers'],\n",
       " ['Scrum.org Group - Not all opinions here are that of Scrum.org or our Trainers',\n",
       "  '32,771 members'],\n",
       " ['Big Data and Analytics', '511,378 members'],\n",
       " ['McGill University', '373,347 followers']]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role_n_exp\n",
    "skill\n",
    "language_list\n",
    "interest_list\n",
    "education_list\n",
    "license_n_cert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ee9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
